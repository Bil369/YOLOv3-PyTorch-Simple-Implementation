{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from utils.config import Config\n",
    "from nets.yolo3 import YoloBody\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader\n",
    "from nets.yolo_training import YOLOLoss, Generator\n",
    "from utils.dataloader import yolo_dataset_collate, YoloDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_one_epoch(net, yolo_losses, epoch, epoch_size, epoch_size_val, gen, genval, Epoch, cuda, optimizer, lr_scheduler):\n",
    "    total_loss = 0\n",
    "    val_loss = 0\n",
    "    print('\\n' + '-' * 10 + 'Train one epoch.' + '-' * 10)\n",
    "    print('Epoch:'+ str(epoch+1) + '/' + str(Epoch))\n",
    "    print('Start Training.')\n",
    "    net.train()\n",
    "    for iteration, batch in enumerate(gen):\n",
    "        start_time = time.time()\n",
    "        if iteration >= epoch_size:\n",
    "            break\n",
    "        images, targets = batch[0], batch[1]\n",
    "        with torch.no_grad():\n",
    "            if cuda:\n",
    "                images = Variable(torch.from_numpy(images).type(torch.FloatTensor)).cuda()\n",
    "                targets = [Variable(torch.from_numpy(ann).type(torch.FloatTensor)) for ann in targets]\n",
    "            else:\n",
    "                images = Variable(torch.from_numpy(images).type(torch.FloatTensor))\n",
    "                targets = [Variable(torch.from_numpy(ann).type(torch.FloatTensor)) for ann in targets]\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(images)\n",
    "        losses = []\n",
    "        for i in range(3):\n",
    "            loss_item = yolo_losses[i](outputs[i], targets)\n",
    "            losses.append(loss_item[0])\n",
    "        loss = sum(losses)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss\n",
    "        waste_time = time.time() - start_time\n",
    "        if iteration == 0 or (iteration+1) % 10 == 0:\n",
    "            print('step:' + str(iteration+1) + '/' + str(epoch_size) + ' || Total Loss: %.4f || %.4fs/step' % (total_loss/(iteration+1), waste_time))\n",
    "    lr_scheduler.step()\n",
    "    print('Finish Training.')\n",
    "\n",
    "    '''\n",
    "    print('Start Validation')\n",
    "    net.eval()\n",
    "    for iteration, batch in enumerate(genval):\n",
    "        if iteration >= epoch_size_val:\n",
    "            break\n",
    "        images_val, targets_val = batch[0], batch[1]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            if cuda:\n",
    "                images_val = Variable(torch.from_numpy(images_val).type(torch.FloatTensor)).cuda()\n",
    "                targets_val = [Variable(torch.from_numpy(ann).type(torch.FloatTensor)) for ann in targets_val]\n",
    "            else:\n",
    "                images_val = Variable(torch.from_numpy(images_val).type(torch.FloatTensor))\n",
    "                targets_val = [Variable(torch.from_numpy(ann).type(torch.FloatTensor)) for ann in targets_val]\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images_val)\n",
    "            losses = []\n",
    "            for i in range(3):\n",
    "                loss_item = yolo_losses[i](outputs[i], targets_val)\n",
    "                losses.append(loss_item[0])\n",
    "            loss = sum(losses)\n",
    "            val_loss += loss\n",
    "    print('Finish Validation')\n",
    "    '''\n",
    "    \n",
    "    print('Total Loss: %.4f || Val Loss: %.4f ' % (total_loss/(epoch_size+1), val_loss/(epoch_size_val+1)))\n",
    "\n",
    "    return total_loss/(epoch_size+1), val_loss/(epoch_size_val+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model weights.\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "# 参数初始化\n",
    "train_annotation_path = 'model_data/voc_train.txt'\n",
    "val_annotation_path = 'model_data/voc_val.txt'\n",
    "model = YoloBody(Config)\n",
    "Cuda = True\n",
    "#-------------------------------#\n",
    "#   Dataloder的使用\n",
    "#-------------------------------#\n",
    "Use_Data_Loader = False\n",
    "\n",
    "print('Loading pretrained model weights.')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_dict = model.state_dict()\n",
    "pretrained_dict = torch.load(\"model_data/yolo_weights.pth\", map_location=device)\n",
    "pretrained_dict = {k: v for k, v in pretrained_dict.items() if np.shape(model_dict[k]) ==  np.shape(v)}\n",
    "model_dict.update(pretrained_dict)\n",
    "model.load_state_dict(model_dict)\n",
    "print('Finished!')\n",
    "\n",
    "if Cuda:\n",
    "    net = torch.nn.DataParallel(model)\n",
    "    cudnn.benchmark = True\n",
    "    net = net.cuda()\n",
    "\n",
    "# 建立loss函数\n",
    "yolo_losses = []\n",
    "for i in range(3):\n",
    "    yolo_losses.append(YOLOLoss(np.reshape(Config[\"yolo\"][\"anchors\"],[-1,2]),\n",
    "                                Config[\"yolo\"][\"classes\"], (Config[\"img_w\"], Config[\"img_h\"]), Cuda))\n",
    "\n",
    "with open(train_annotation_path) as f:\n",
    "    train_lines = f.readlines()\n",
    "with open(val_annotation_path) as f:\n",
    "    val_lines = f.readlines()\n",
    "num_train = len(train_lines)\n",
    "num_val = len(val_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------Train one epoch.----------\n",
      "Epoch:1/25\n",
      "Start Training.\n",
      "step:1/156 || Total Loss: 7803.9331 || 2.0100s/step\n",
      "step:10/156 || Total Loss: 3594.3267 || 0.4677s/step\n",
      "step:20/156 || Total Loss: 2108.3865 || 0.5276s/step\n",
      "step:30/156 || Total Loss: 1486.1564 || 0.4780s/step\n",
      "step:40/156 || Total Loss: 1150.4677 || 0.4558s/step\n",
      "step:50/156 || Total Loss: 941.8665 || 0.4864s/step\n",
      "step:60/156 || Total Loss: 799.6990 || 0.4587s/step\n",
      "step:70/156 || Total Loss: 697.1407 || 0.4572s/step\n",
      "step:80/156 || Total Loss: 619.0457 || 0.4835s/step\n",
      "step:90/156 || Total Loss: 557.6161 || 0.4859s/step\n",
      "step:100/156 || Total Loss: 507.9505 || 0.4769s/step\n",
      "step:110/156 || Total Loss: 466.9517 || 0.4825s/step\n",
      "step:120/156 || Total Loss: 432.6122 || 0.4912s/step\n",
      "step:130/156 || Total Loss: 403.4812 || 0.5004s/step\n",
      "step:140/156 || Total Loss: 377.9802 || 0.4966s/step\n",
      "step:150/156 || Total Loss: 355.8572 || 0.4681s/step\n",
      "Finish Training.\n",
      "Total Loss: 341.5372 || Val Loss: 0.0000 \n",
      "\n",
      "----------Train one epoch.----------\n",
      "Epoch:2/25\n",
      "Start Training.\n",
      "step:1/156 || Total Loss: 44.6204 || 0.5037s/step\n",
      "step:10/156 || Total Loss: 44.9902 || 0.5323s/step\n",
      "step:20/156 || Total Loss: 43.4748 || 0.5192s/step\n",
      "step:30/156 || Total Loss: 42.6132 || 0.5332s/step\n",
      "step:40/156 || Total Loss: 41.3184 || 0.4976s/step\n",
      "step:50/156 || Total Loss: 40.4129 || 0.5297s/step\n",
      "step:60/156 || Total Loss: 39.6863 || 0.4913s/step\n",
      "step:70/156 || Total Loss: 38.5174 || 0.4533s/step\n",
      "step:80/156 || Total Loss: 37.6396 || 0.4835s/step\n",
      "step:90/156 || Total Loss: 37.1805 || 0.4943s/step\n",
      "step:100/156 || Total Loss: 36.8378 || 0.4955s/step\n",
      "step:110/156 || Total Loss: 36.2168 || 0.4967s/step\n",
      "step:120/156 || Total Loss: 35.5500 || 0.5010s/step\n",
      "step:130/156 || Total Loss: 35.3679 || 0.4752s/step\n",
      "step:140/156 || Total Loss: 34.8315 || 0.4599s/step\n",
      "step:150/156 || Total Loss: 34.3977 || 0.4627s/step\n",
      "Finish Training.\n",
      "Total Loss: 34.1178 || Val Loss: 0.0000 \n",
      "\n",
      "----------Train one epoch.----------\n",
      "Epoch:3/25\n",
      "Start Training.\n",
      "step:1/156 || Total Loss: 28.7144 || 0.4961s/step\n",
      "step:10/156 || Total Loss: 27.3369 || 0.4698s/step\n",
      "step:20/156 || Total Loss: 27.1201 || 0.4708s/step\n",
      "step:30/156 || Total Loss: 27.1236 || 0.4732s/step\n",
      "step:40/156 || Total Loss: 26.8023 || 0.4920s/step\n",
      "step:50/156 || Total Loss: 26.2080 || 0.4785s/step\n",
      "step:60/156 || Total Loss: 25.9058 || 0.4879s/step\n",
      "step:70/156 || Total Loss: 25.9315 || 0.4846s/step\n",
      "step:80/156 || Total Loss: 25.9204 || 0.5150s/step\n",
      "step:90/156 || Total Loss: 25.9891 || 0.5448s/step\n",
      "step:100/156 || Total Loss: 25.7971 || 0.4496s/step\n",
      "step:110/156 || Total Loss: 25.6881 || 0.4574s/step\n",
      "step:120/156 || Total Loss: 25.6289 || 0.4820s/step\n",
      "step:130/156 || Total Loss: 25.3879 || 0.5083s/step\n",
      "step:140/156 || Total Loss: 25.3875 || 0.5421s/step\n",
      "step:150/156 || Total Loss: 25.2981 || 0.4589s/step\n",
      "Finish Training.\n",
      "Total Loss: 24.9429 || Val Loss: 0.0000 \n",
      "\n",
      "----------Train one epoch.----------\n",
      "Epoch:4/25\n",
      "Start Training.\n",
      "step:1/156 || Total Loss: 26.1204 || 0.4945s/step\n",
      "step:10/156 || Total Loss: 24.0563 || 0.4592s/step\n",
      "step:20/156 || Total Loss: 22.6998 || 0.4749s/step\n",
      "step:30/156 || Total Loss: 23.0563 || 0.5370s/step\n",
      "step:40/156 || Total Loss: 22.3750 || 0.5108s/step\n",
      "step:50/156 || Total Loss: 22.4880 || 0.4738s/step\n",
      "step:60/156 || Total Loss: 22.4239 || 0.4564s/step\n",
      "step:70/156 || Total Loss: 22.2959 || 0.4826s/step\n",
      "step:80/156 || Total Loss: 22.1630 || 0.5284s/step\n",
      "step:90/156 || Total Loss: 22.0357 || 0.5075s/step\n",
      "step:100/156 || Total Loss: 21.9064 || 0.4833s/step\n",
      "step:110/156 || Total Loss: 21.8415 || 0.4971s/step\n",
      "step:120/156 || Total Loss: 21.6865 || 0.4902s/step\n",
      "step:130/156 || Total Loss: 21.7476 || 0.5572s/step\n",
      "step:140/156 || Total Loss: 21.8239 || 0.4763s/step\n",
      "step:150/156 || Total Loss: 21.6159 || 0.4777s/step\n",
      "Finish Training.\n",
      "Total Loss: 21.4422 || Val Loss: 0.0000 \n",
      "\n",
      "----------Train one epoch.----------\n",
      "Epoch:5/25\n",
      "Start Training.\n",
      "step:1/156 || Total Loss: 25.2829 || 0.5116s/step\n",
      "step:10/156 || Total Loss: 18.7819 || 0.5081s/step\n",
      "step:20/156 || Total Loss: 19.2213 || 0.5238s/step\n",
      "step:30/156 || Total Loss: 19.2238 || 0.5021s/step\n",
      "step:40/156 || Total Loss: 19.0417 || 0.4629s/step\n",
      "step:50/156 || Total Loss: 19.1540 || 0.5243s/step\n",
      "step:60/156 || Total Loss: 19.3279 || 0.4771s/step\n",
      "step:70/156 || Total Loss: 19.3666 || 0.4515s/step\n",
      "step:80/156 || Total Loss: 19.4224 || 0.4766s/step\n",
      "step:90/156 || Total Loss: 19.5315 || 0.5116s/step\n",
      "step:100/156 || Total Loss: 19.4142 || 0.4659s/step\n",
      "step:110/156 || Total Loss: 19.2805 || 0.4884s/step\n",
      "step:120/156 || Total Loss: 19.3016 || 0.5061s/step\n",
      "step:130/156 || Total Loss: 19.0825 || 0.4578s/step\n",
      "step:140/156 || Total Loss: 19.0801 || 0.5150s/step\n",
      "step:150/156 || Total Loss: 19.0534 || 0.4925s/step\n",
      "Finish Training.\n",
      "Total Loss: 18.7761 || Val Loss: 0.0000 \n",
      "\n",
      "----------Train one epoch.----------\n",
      "Epoch:6/25\n",
      "Start Training.\n",
      "step:1/156 || Total Loss: 16.7577 || 0.4794s/step\n",
      "step:10/156 || Total Loss: 18.0702 || 0.4504s/step\n",
      "step:30/156 || Total Loss: 17.4586 || 0.4486s/step\n",
      "step:40/156 || Total Loss: 17.5677 || 0.4884s/step\n",
      "step:50/156 || Total Loss: 17.7486 || 0.4772s/step\n",
      "step:60/156 || Total Loss: 17.7600 || 0.4636s/step\n",
      "step:70/156 || Total Loss: 17.7317 || 0.4784s/step\n",
      "step:80/156 || Total Loss: 17.8452 || 0.4900s/step\n",
      "step:90/156 || Total Loss: 17.7472 || 0.4741s/step\n",
      "step:110/156 || Total Loss: 17.8575 || 0.4559s/step\n",
      "step:120/156 || Total Loss: 17.7596 || 0.5341s/step\n",
      "step:130/156 || Total Loss: 17.8237 || 0.5060s/step\n",
      "step:140/156 || Total Loss: 18.0402 || 0.4819s/step\n",
      "step:150/156 || Total Loss: 18.1426 || 0.4747s/step\n",
      "Finish Training.\n",
      "Total Loss: 17.9919 || Val Loss: 0.0000 \n",
      "\n",
      "----------Train one epoch.----------\n",
      "Epoch:7/25\n",
      "Start Training.\n",
      "step:1/156 || Total Loss: 16.6296 || 0.4851s/step\n",
      "step:10/156 || Total Loss: 17.5150 || 0.5024s/step\n",
      "step:20/156 || Total Loss: 17.3966 || 0.5151s/step\n",
      "step:30/156 || Total Loss: 17.4055 || 0.4861s/step\n",
      "step:40/156 || Total Loss: 17.8560 || 0.5271s/step\n",
      "step:50/156 || Total Loss: 17.8445 || 0.4619s/step\n",
      "step:60/156 || Total Loss: 17.8588 || 0.4965s/step\n",
      "step:70/156 || Total Loss: 17.7187 || 0.5433s/step\n",
      "step:80/156 || Total Loss: 17.7654 || 0.4858s/step\n",
      "step:90/156 || Total Loss: 17.6982 || 0.4869s/step\n",
      "step:100/156 || Total Loss: 17.5018 || 0.4824s/step\n",
      "step:110/156 || Total Loss: 17.6076 || 0.4862s/step\n",
      "step:120/156 || Total Loss: 17.6904 || 0.4419s/step\n",
      "step:130/156 || Total Loss: 17.5048 || 0.4837s/step\n",
      "step:140/156 || Total Loss: 17.3943 || 0.4251s/step\n",
      "step:150/156 || Total Loss: 17.2788 || 0.5244s/step\n",
      "Finish Training.\n",
      "Total Loss: 17.1269 || Val Loss: 0.0000 \n",
      "\n",
      "----------Train one epoch.----------\n",
      "Epoch:8/25\n",
      "Start Training.\n",
      "step:1/156 || Total Loss: 33.7649 || 0.5729s/step\n",
      "step:10/156 || Total Loss: 20.2397 || 0.5132s/step\n",
      "step:20/156 || Total Loss: 18.3952 || 0.5021s/step\n",
      "step:30/156 || Total Loss: 17.7525 || 0.4837s/step\n",
      "step:40/156 || Total Loss: 17.4479 || 0.4598s/step\n",
      "step:50/156 || Total Loss: 17.3697 || 0.4564s/step\n",
      "step:60/156 || Total Loss: 17.2344 || 0.5358s/step\n",
      "step:70/156 || Total Loss: 17.0819 || 0.4758s/step\n",
      "step:80/156 || Total Loss: 16.9305 || 0.4719s/step\n",
      "step:90/156 || Total Loss: 16.9637 || 0.4614s/step\n",
      "step:100/156 || Total Loss: 16.9069 || 0.4948s/step\n",
      "step:110/156 || Total Loss: 16.8073 || 0.4619s/step\n",
      "step:120/156 || Total Loss: 16.7312 || 0.4853s/step\n",
      "step:130/156 || Total Loss: 16.7232 || 0.5221s/step\n",
      "step:140/156 || Total Loss: 16.6001 || 0.4863s/step\n",
      "step:150/156 || Total Loss: 16.6285 || 0.4683s/step\n",
      "Finish Training.\n",
      "Total Loss: 16.5610 || Val Loss: 0.0000 \n",
      "\n",
      "----------Train one epoch.----------\n",
      "Epoch:9/25\n",
      "Start Training.\n",
      "step:1/156 || Total Loss: 19.3934 || 0.4997s/step\n",
      "step:10/156 || Total Loss: 18.8824 || 0.4699s/step\n",
      "step:20/156 || Total Loss: 16.5150 || 0.4557s/step\n",
      "step:30/156 || Total Loss: 16.5729 || 0.5177s/step\n",
      "step:40/156 || Total Loss: 16.3434 || 0.4606s/step\n",
      "step:50/156 || Total Loss: 16.1875 || 0.4901s/step\n",
      "step:60/156 || Total Loss: 16.1705 || 0.5023s/step\n",
      "step:70/156 || Total Loss: 16.0232 || 0.5058s/step\n",
      "step:80/156 || Total Loss: 15.7153 || 0.4786s/step\n",
      "step:90/156 || Total Loss: 15.5062 || 0.4552s/step\n",
      "step:100/156 || Total Loss: 15.6486 || 0.4764s/step\n",
      "step:110/156 || Total Loss: 15.6361 || 0.4874s/step\n",
      "step:120/156 || Total Loss: 15.7891 || 0.5127s/step\n",
      "step:130/156 || Total Loss: 15.6835 || 0.4496s/step\n",
      "step:140/156 || Total Loss: 15.6630 || 0.4656s/step\n",
      "step:150/156 || Total Loss: 15.7660 || 0.4958s/step\n",
      "Finish Training.\n",
      "Total Loss: 15.5749 || Val Loss: 0.0000 \n",
      "\n",
      "----------Train one epoch.----------\n",
      "Epoch:10/25\n",
      "Start Training.\n",
      "step:1/156 || Total Loss: 19.1421 || 0.5165s/step\n",
      "step:10/156 || Total Loss: 17.3138 || 0.5533s/step\n",
      "step:20/156 || Total Loss: 16.1625 || 0.4702s/step\n",
      "step:30/156 || Total Loss: 15.8862 || 0.5499s/step\n",
      "step:40/156 || Total Loss: 15.8497 || 0.5216s/step\n",
      "step:50/156 || Total Loss: 15.8542 || 0.4680s/step\n",
      "step:60/156 || Total Loss: 15.9103 || 0.4899s/step\n",
      "step:70/156 || Total Loss: 16.0943 || 0.4941s/step\n",
      "step:80/156 || Total Loss: 16.0907 || 0.4831s/step\n",
      "step:90/156 || Total Loss: 16.0106 || 0.4768s/step\n",
      "step:100/156 || Total Loss: 15.8252 || 0.4726s/step\n",
      "step:110/156 || Total Loss: 15.6547 || 0.4627s/step\n",
      "step:120/156 || Total Loss: 15.6459 || 0.4941s/step\n",
      "step:130/156 || Total Loss: 15.6756 || 0.5069s/step\n",
      "step:140/156 || Total Loss: 15.5777 || 0.4703s/step\n",
      "step:150/156 || Total Loss: 15.4083 || 0.4424s/step\n",
      "Finish Training.\n",
      "Total Loss: 15.3497 || Val Loss: 0.0000 \n",
      "\n",
      "----------Train one epoch.----------\n",
      "Epoch:11/25\n",
      "Start Training.\n",
      "step:1/156 || Total Loss: 13.0036 || 0.4633s/step\n",
      "step:10/156 || Total Loss: 14.2991 || 0.4820s/step\n",
      "step:20/156 || Total Loss: 14.4168 || 0.4583s/step\n",
      "step:30/156 || Total Loss: 14.5787 || 0.4759s/step\n",
      "step:40/156 || Total Loss: 14.7284 || 0.4479s/step\n",
      "step:50/156 || Total Loss: 14.9032 || 0.5071s/step\n",
      "step:60/156 || Total Loss: 15.0917 || 0.5437s/step\n",
      "step:70/156 || Total Loss: 14.9216 || 0.4593s/step\n",
      "step:80/156 || Total Loss: 15.0862 || 0.4940s/step\n",
      "step:90/156 || Total Loss: 15.0406 || 0.4898s/step\n",
      "step:100/156 || Total Loss: 14.9674 || 0.4581s/step\n",
      "step:110/156 || Total Loss: 14.9389 || 0.4954s/step\n",
      "step:120/156 || Total Loss: 15.0030 || 0.5111s/step\n",
      "step:130/156 || Total Loss: 15.0689 || 0.4811s/step\n",
      "step:140/156 || Total Loss: 15.0254 || 0.4953s/step\n",
      "step:150/156 || Total Loss: 14.9618 || 0.4974s/step\n",
      "Finish Training.\n",
      "Total Loss: 14.8285 || Val Loss: 0.0000 \n",
      "\n",
      "----------Train one epoch.----------\n",
      "Epoch:12/25\n",
      "Start Training.\n",
      "step:1/156 || Total Loss: 14.2498 || 0.4845s/step\n",
      "step:10/156 || Total Loss: 13.8161 || 0.4791s/step\n",
      "step:20/156 || Total Loss: 15.5179 || 0.5536s/step\n",
      "step:30/156 || Total Loss: 15.6114 || 0.5740s/step\n",
      "step:40/156 || Total Loss: 15.2803 || 0.4866s/step\n",
      "step:50/156 || Total Loss: 15.0481 || 0.4561s/step\n",
      "step:60/156 || Total Loss: 15.0532 || 0.4523s/step\n",
      "step:70/156 || Total Loss: 14.8812 || 0.5110s/step\n",
      "step:80/156 || Total Loss: 14.7843 || 0.4495s/step\n",
      "step:90/156 || Total Loss: 14.7912 || 0.5124s/step\n",
      "step:100/156 || Total Loss: 14.6541 || 0.4772s/step\n",
      "step:110/156 || Total Loss: 14.6940 || 0.4687s/step\n",
      "step:120/156 || Total Loss: 14.7574 || 0.4955s/step\n",
      "step:130/156 || Total Loss: 14.6979 || 0.4656s/step\n",
      "step:140/156 || Total Loss: 14.8137 || 0.4798s/step\n",
      "step:150/156 || Total Loss: 14.8560 || 0.4899s/step\n",
      "Finish Training.\n",
      "Total Loss: 14.7522 || Val Loss: 0.0000 \n",
      "\n",
      "----------Train one epoch.----------\n",
      "Epoch:13/25\n",
      "Start Training.\n",
      "step:1/156 || Total Loss: 13.9849 || 0.4815s/step\n",
      "step:10/156 || Total Loss: 14.7269 || 0.5703s/step\n",
      "step:20/156 || Total Loss: 14.9646 || 0.5129s/step\n",
      "step:30/156 || Total Loss: 15.2155 || 0.5242s/step\n",
      "step:40/156 || Total Loss: 15.0631 || 0.5343s/step\n",
      "step:50/156 || Total Loss: 15.2079 || 0.4462s/step\n",
      "step:60/156 || Total Loss: 15.1599 || 0.4860s/step\n",
      "step:70/156 || Total Loss: 15.1247 || 0.4698s/step\n",
      "step:80/156 || Total Loss: 15.0531 || 0.4881s/step\n",
      "step:90/156 || Total Loss: 14.8358 || 0.4643s/step\n",
      "step:100/156 || Total Loss: 14.8015 || 0.4773s/step\n",
      "step:110/156 || Total Loss: 14.7435 || 0.4847s/step\n",
      "step:120/156 || Total Loss: 14.8615 || 0.5130s/step\n",
      "step:130/156 || Total Loss: 14.8296 || 0.4538s/step\n",
      "step:140/156 || Total Loss: 14.8258 || 0.5507s/step\n",
      "step:150/156 || Total Loss: 14.6568 || 0.4604s/step\n",
      "Finish Training.\n",
      "Total Loss: 14.5151 || Val Loss: 0.0000 \n",
      "\n",
      "----------Train one epoch.----------\n",
      "Epoch:14/25\n",
      "Start Training.\n",
      "step:1/156 || Total Loss: 13.1608 || 0.4744s/step\n",
      "step:10/156 || Total Loss: 14.7189 || 0.5628s/step\n",
      "step:20/156 || Total Loss: 14.0781 || 0.4966s/step\n",
      "step:30/156 || Total Loss: 13.9209 || 0.4529s/step\n",
      "step:40/156 || Total Loss: 13.6584 || 0.4859s/step\n",
      "step:50/156 || Total Loss: 13.6667 || 0.4623s/step\n",
      "step:60/156 || Total Loss: 13.7855 || 0.5239s/step\n",
      "step:70/156 || Total Loss: 14.0754 || 0.4941s/step\n",
      "step:80/156 || Total Loss: 14.0470 || 0.4821s/step\n",
      "step:90/156 || Total Loss: 14.0663 || 0.4740s/step\n",
      "step:100/156 || Total Loss: 14.0265 || 0.5011s/step\n",
      "step:110/156 || Total Loss: 13.9174 || 0.4818s/step\n",
      "step:120/156 || Total Loss: 13.9754 || 0.4707s/step\n",
      "step:130/156 || Total Loss: 13.9671 || 0.5275s/step\n",
      "step:140/156 || Total Loss: 13.9872 || 0.5052s/step\n",
      "step:150/156 || Total Loss: 14.0633 || 0.4841s/step\n",
      "Finish Training.\n",
      "Total Loss: 13.9047 || Val Loss: 0.0000 \n",
      "\n",
      "----------Train one epoch.----------\n",
      "Epoch:15/25\n",
      "Start Training.\n",
      "step:1/156 || Total Loss: 15.8983 || 0.4977s/step\n",
      "step:10/156 || Total Loss: 13.8161 || 0.4658s/step\n",
      "step:20/156 || Total Loss: 13.1377 || 0.5041s/step\n",
      "step:30/156 || Total Loss: 13.2767 || 0.5091s/step\n",
      "step:40/156 || Total Loss: 13.4355 || 0.5216s/step\n",
      "step:50/156 || Total Loss: 13.5702 || 0.4444s/step\n",
      "step:60/156 || Total Loss: 13.6558 || 0.4667s/step\n",
      "step:70/156 || Total Loss: 13.7051 || 0.4847s/step\n",
      "step:80/156 || Total Loss: 13.7183 || 0.4807s/step\n",
      "step:90/156 || Total Loss: 13.9159 || 0.4934s/step\n",
      "step:110/156 || Total Loss: 13.9181 || 0.4521s/step\n",
      "step:120/156 || Total Loss: 13.8990 || 0.5409s/step\n",
      "step:130/156 || Total Loss: 13.9738 || 0.5201s/step\n",
      "step:140/156 || Total Loss: 14.0532 || 0.5190s/step\n",
      "step:150/156 || Total Loss: 13.9765 || 0.4939s/step\n",
      "Finish Training.\n",
      "Total Loss: 13.9666 || Val Loss: 0.0000 \n",
      "\n",
      "----------Train one epoch.----------\n",
      "Epoch:16/25\n",
      "Start Training.\n",
      "step:1/156 || Total Loss: 8.7739 || 0.4425s/step\n",
      "step:10/156 || Total Loss: 16.0299 || 0.4984s/step\n",
      "step:20/156 || Total Loss: 16.3798 || 0.5280s/step\n",
      "step:30/156 || Total Loss: 15.2158 || 0.4871s/step\n",
      "step:40/156 || Total Loss: 14.7523 || 0.4728s/step\n",
      "step:50/156 || Total Loss: 14.3526 || 0.4349s/step\n",
      "step:60/156 || Total Loss: 14.3185 || 0.4461s/step\n",
      "step:70/156 || Total Loss: 14.0935 || 0.4676s/step\n",
      "step:80/156 || Total Loss: 14.0960 || 0.4649s/step\n",
      "step:100/156 || Total Loss: 13.9424 || 0.4769s/step\n",
      "step:110/156 || Total Loss: 13.8457 || 0.4839s/step\n",
      "step:120/156 || Total Loss: 13.8261 || 0.4757s/step\n",
      "step:130/156 || Total Loss: 13.8318 || 0.4646s/step\n",
      "step:140/156 || Total Loss: 13.8088 || 0.4876s/step\n",
      "step:150/156 || Total Loss: 13.6821 || 0.4720s/step\n",
      "Finish Training.\n",
      "Total Loss: 13.5736 || Val Loss: 0.0000 \n",
      "\n",
      "----------Train one epoch.----------\n",
      "Epoch:17/25\n",
      "Start Training.\n",
      "step:1/156 || Total Loss: 18.7045 || 0.5180s/step\n",
      "step:10/156 || Total Loss: 14.1571 || 0.4784s/step\n",
      "step:20/156 || Total Loss: 13.4639 || 0.6909s/step\n",
      "step:30/156 || Total Loss: 14.0792 || 0.4978s/step\n",
      "step:40/156 || Total Loss: 13.9195 || 0.5083s/step\n",
      "step:50/156 || Total Loss: 13.6201 || 0.4512s/step\n",
      "step:60/156 || Total Loss: 13.7873 || 0.5360s/step\n",
      "step:70/156 || Total Loss: 13.7181 || 0.5250s/step\n",
      "step:80/156 || Total Loss: 13.7378 || 0.4820s/step\n",
      "step:90/156 || Total Loss: 13.6976 || 0.5448s/step\n",
      "step:100/156 || Total Loss: 13.7946 || 0.4974s/step\n",
      "step:110/156 || Total Loss: 13.9708 || 0.4954s/step\n",
      "step:120/156 || Total Loss: 13.9640 || 0.5191s/step\n",
      "step:130/156 || Total Loss: 13.8613 || 0.5212s/step\n",
      "step:140/156 || Total Loss: 13.8745 || 0.4811s/step\n",
      "step:150/156 || Total Loss: 13.8311 || 0.5295s/step\n",
      "Finish Training.\n",
      "Total Loss: 13.6802 || Val Loss: 0.0000 \n",
      "\n",
      "----------Train one epoch.----------\n",
      "Epoch:18/25\n",
      "Start Training.\n",
      "step:1/156 || Total Loss: 16.7730 || 0.5187s/step\n",
      "step:20/156 || Total Loss: 13.5873 || 0.4960s/step\n",
      "step:30/156 || Total Loss: 13.9781 || 0.5119s/step\n",
      "step:40/156 || Total Loss: 13.7259 || 0.4720s/step\n",
      "step:50/156 || Total Loss: 13.7788 || 0.5280s/step\n",
      "step:60/156 || Total Loss: 14.0999 || 0.5507s/step\n",
      "step:70/156 || Total Loss: 13.7594 || 0.4622s/step\n",
      "step:80/156 || Total Loss: 13.6983 || 0.4450s/step\n",
      "step:90/156 || Total Loss: 13.5838 || 0.6711s/step\n",
      "step:100/156 || Total Loss: 13.5781 || 0.4717s/step\n",
      "step:110/156 || Total Loss: 13.5226 || 0.4663s/step\n",
      "step:120/156 || Total Loss: 13.5459 || 0.4693s/step\n",
      "step:130/156 || Total Loss: 13.5135 || 0.5171s/step\n",
      "step:140/156 || Total Loss: 13.4757 || 0.4866s/step\n",
      "step:150/156 || Total Loss: 13.5022 || 0.4753s/step\n",
      "Finish Training.\n",
      "Total Loss: 13.4485 || Val Loss: 0.0000 \n",
      "\n",
      "----------Train one epoch.----------\n",
      "Epoch:19/25\n",
      "Start Training.\n",
      "step:1/156 || Total Loss: 11.8544 || 0.5154s/step\n",
      "step:10/156 || Total Loss: 14.1762 || 0.5652s/step\n",
      "step:20/156 || Total Loss: 13.5290 || 0.5138s/step\n",
      "step:30/156 || Total Loss: 13.3671 || 0.4905s/step\n",
      "step:40/156 || Total Loss: 13.0361 || 0.4686s/step\n",
      "step:50/156 || Total Loss: 12.8357 || 0.6308s/step\n",
      "step:60/156 || Total Loss: 13.1197 || 0.6393s/step\n",
      "step:70/156 || Total Loss: 13.2368 || 0.6371s/step\n",
      "step:80/156 || Total Loss: 13.2999 || 0.6492s/step\n",
      "step:90/156 || Total Loss: 13.2432 || 0.6514s/step\n",
      "step:100/156 || Total Loss: 13.2400 || 0.6212s/step\n",
      "step:110/156 || Total Loss: 13.2123 || 0.4942s/step\n",
      "step:120/156 || Total Loss: 13.1831 || 0.5624s/step\n",
      "step:130/156 || Total Loss: 13.1837 || 0.5785s/step\n",
      "step:140/156 || Total Loss: 13.1940 || 0.6479s/step\n",
      "Finish Training.\n",
      "Total Loss: 13.1499 || Val Loss: 0.0000 \n",
      "\n",
      "----------Train one epoch.----------\n",
      "Epoch:20/25\n",
      "Start Training.\n",
      "step:1/156 || Total Loss: 17.7788 || 0.7106s/step\n",
      "step:10/156 || Total Loss: 12.7337 || 0.5955s/step\n",
      "step:20/156 || Total Loss: 12.9547 || 0.6682s/step\n",
      "step:30/156 || Total Loss: 13.2253 || 0.6640s/step\n",
      "step:40/156 || Total Loss: 13.3128 || 0.6536s/step\n",
      "step:50/156 || Total Loss: 13.4278 || 0.6904s/step\n",
      "step:60/156 || Total Loss: 13.4737 || 0.6583s/step\n",
      "step:70/156 || Total Loss: 13.4271 || 0.6414s/step\n",
      "step:80/156 || Total Loss: 13.2606 || 0.6311s/step\n",
      "step:90/156 || Total Loss: 13.2009 || 0.6710s/step\n",
      "step:100/156 || Total Loss: 13.2339 || 0.6792s/step\n",
      "step:110/156 || Total Loss: 13.1695 || 0.6428s/step\n",
      "step:120/156 || Total Loss: 13.1786 || 0.7084s/step\n",
      "step:130/156 || Total Loss: 13.1744 || 0.6157s/step\n",
      "step:140/156 || Total Loss: 13.0876 || 0.5774s/step\n",
      "step:150/156 || Total Loss: 13.1380 || 0.6191s/step\n",
      "Finish Training.\n",
      "Total Loss: 12.9958 || Val Loss: 0.0000 \n",
      "\n",
      "----------Train one epoch.----------\n",
      "Epoch:21/25\n",
      "Start Training.\n",
      "step:1/156 || Total Loss: 13.0525 || 0.6534s/step\n",
      "step:10/156 || Total Loss: 13.7028 || 0.7041s/step\n",
      "step:20/156 || Total Loss: 12.7619 || 0.5985s/step\n",
      "step:30/156 || Total Loss: 13.0580 || 0.7015s/step\n",
      "step:40/156 || Total Loss: 13.0608 || 0.6684s/step\n",
      "step:50/156 || Total Loss: 13.0847 || 0.5420s/step\n",
      "step:60/156 || Total Loss: 12.8468 || 0.6461s/step\n",
      "step:70/156 || Total Loss: 13.0297 || 0.6363s/step\n",
      "step:80/156 || Total Loss: 13.0544 || 0.7314s/step\n",
      "step:90/156 || Total Loss: 13.0594 || 0.6314s/step\n",
      "step:100/156 || Total Loss: 13.0907 || 0.6080s/step\n",
      "step:110/156 || Total Loss: 13.0639 || 0.6418s/step\n",
      "step:120/156 || Total Loss: 13.0418 || 0.6149s/step\n",
      "step:130/156 || Total Loss: 12.9180 || 0.5961s/step\n",
      "step:140/156 || Total Loss: 12.8703 || 0.5926s/step\n",
      "step:150/156 || Total Loss: 12.8277 || 0.6305s/step\n",
      "Finish Training.\n",
      "Total Loss: 12.7635 || Val Loss: 0.0000 \n",
      "\n",
      "----------Train one epoch.----------\n",
      "Epoch:22/25\n",
      "Start Training.\n",
      "step:1/156 || Total Loss: 13.8783 || 0.6949s/step\n",
      "step:10/156 || Total Loss: 12.1084 || 0.4867s/step\n",
      "step:20/156 || Total Loss: 12.4670 || 0.5229s/step\n",
      "step:30/156 || Total Loss: 12.9162 || 0.5393s/step\n",
      "step:40/156 || Total Loss: 12.7038 || 0.4957s/step\n",
      "step:50/156 || Total Loss: 13.1176 || 0.4815s/step\n",
      "step:60/156 || Total Loss: 13.3452 || 0.5508s/step\n",
      "step:70/156 || Total Loss: 13.2823 || 0.4624s/step\n",
      "step:80/156 || Total Loss: 13.1134 || 0.4624s/step\n",
      "step:90/156 || Total Loss: 12.9469 || 0.4628s/step\n",
      "step:100/156 || Total Loss: 12.8767 || 0.5047s/step\n",
      "step:110/156 || Total Loss: 12.8602 || 0.4786s/step\n",
      "step:120/156 || Total Loss: 12.8893 || 0.4805s/step\n",
      "step:130/156 || Total Loss: 12.7688 || 0.4765s/step\n",
      "step:140/156 || Total Loss: 12.7112 || 0.4584s/step\n",
      "step:150/156 || Total Loss: 12.7803 || 0.5065s/step\n",
      "Finish Training.\n",
      "Total Loss: 12.6774 || Val Loss: 0.0000 \n",
      "\n",
      "----------Train one epoch.----------\n",
      "Epoch:23/25\n",
      "Start Training.\n",
      "step:1/156 || Total Loss: 11.1150 || 0.4789s/step\n",
      "step:10/156 || Total Loss: 12.7430 || 0.5352s/step\n",
      "step:20/156 || Total Loss: 12.5030 || 0.4884s/step\n",
      "step:30/156 || Total Loss: 12.5180 || 0.4732s/step\n",
      "step:40/156 || Total Loss: 12.1626 || 0.4636s/step\n",
      "step:50/156 || Total Loss: 12.2727 || 0.5246s/step\n",
      "step:60/156 || Total Loss: 12.0822 || 0.5094s/step\n",
      "step:70/156 || Total Loss: 12.3443 || 0.4786s/step\n",
      "step:80/156 || Total Loss: 12.4218 || 0.5181s/step\n",
      "step:90/156 || Total Loss: 12.5323 || 0.5332s/step\n",
      "step:100/156 || Total Loss: 12.6454 || 0.5191s/step\n",
      "step:110/156 || Total Loss: 12.7681 || 0.4606s/step\n",
      "step:120/156 || Total Loss: 12.6325 || 0.5338s/step\n",
      "step:130/156 || Total Loss: 12.6409 || 0.5178s/step\n",
      "step:140/156 || Total Loss: 12.6601 || 0.4857s/step\n",
      "step:150/156 || Total Loss: 12.6468 || 0.5399s/step\n",
      "Finish Training.\n",
      "Total Loss: 12.5502 || Val Loss: 0.0000 \n",
      "\n",
      "----------Train one epoch.----------\n",
      "Epoch:24/25\n",
      "Start Training.\n",
      "step:1/156 || Total Loss: 13.5330 || 0.4978s/step\n",
      "step:10/156 || Total Loss: 13.1905 || 0.4910s/step\n",
      "step:20/156 || Total Loss: 13.3401 || 0.5180s/step\n",
      "step:30/156 || Total Loss: 12.8998 || 0.4595s/step\n",
      "step:40/156 || Total Loss: 12.8657 || 0.4838s/step\n",
      "step:50/156 || Total Loss: 12.6688 || 0.4798s/step\n",
      "step:60/156 || Total Loss: 12.4896 || 0.5366s/step\n",
      "step:70/156 || Total Loss: 12.7010 || 0.5114s/step\n",
      "step:80/156 || Total Loss: 12.6698 || 0.5453s/step\n",
      "step:90/156 || Total Loss: 12.5472 || 0.5111s/step\n",
      "step:100/156 || Total Loss: 12.6004 || 0.4756s/step\n",
      "step:110/156 || Total Loss: 12.4761 || 0.5047s/step\n",
      "step:120/156 || Total Loss: 12.5116 || 0.4903s/step\n",
      "step:130/156 || Total Loss: 12.4821 || 0.5195s/step\n",
      "step:140/156 || Total Loss: 12.4359 || 0.4665s/step\n",
      "step:150/156 || Total Loss: 12.3786 || 0.5262s/step\n",
      "Finish Training.\n",
      "Total Loss: 12.2913 || Val Loss: 0.0000 \n",
      "\n",
      "----------Train one epoch.----------\n",
      "Epoch:25/25\n",
      "Start Training.\n",
      "step:1/156 || Total Loss: 11.6138 || 0.4889s/step\n",
      "step:10/156 || Total Loss: 11.3816 || 0.5071s/step\n",
      "step:20/156 || Total Loss: 11.6524 || 0.5142s/step\n",
      "step:30/156 || Total Loss: 11.9893 || 0.4848s/step\n",
      "step:40/156 || Total Loss: 11.8906 || 0.5050s/step\n",
      "step:50/156 || Total Loss: 11.9957 || 0.5152s/step\n",
      "step:60/156 || Total Loss: 12.0165 || 0.5027s/step\n",
      "step:70/156 || Total Loss: 12.1566 || 0.4973s/step\n",
      "step:80/156 || Total Loss: 12.2719 || 0.5114s/step\n",
      "step:90/156 || Total Loss: 12.2642 || 0.4800s/step\n",
      "step:100/156 || Total Loss: 12.4990 || 0.5286s/step\n",
      "step:110/156 || Total Loss: 12.4460 || 0.5040s/step\n",
      "step:120/156 || Total Loss: 12.5424 || 0.4683s/step\n",
      "step:130/156 || Total Loss: 12.5076 || 0.5017s/step\n",
      "step:140/156 || Total Loss: 12.5488 || 0.5244s/step\n",
      "step:150/156 || Total Loss: 12.6461 || 0.4492s/step\n",
      "Finish Training.\n",
      "Total Loss: 12.6390 || Val Loss: 0.0000 \n"
     ]
    }
   ],
   "source": [
    "#------------------------------------#\n",
    "#   冻结一定部分训练\n",
    "#------------------------------------#\n",
    "lr = 1e-3\n",
    "Batch_size = 32\n",
    "Init_Epoch = 0\n",
    "Freeze_Epoch = 25\n",
    "        \n",
    "optimizer = optim.Adam(net.parameters(), lr)\n",
    "#optimizer = optim.SGD(net.parameters(), lr, momentum=0.9, weight_decay=0.0005)\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)\n",
    "\n",
    "if Use_Data_Loader:\n",
    "    train_dataset = YoloDataset(train_lines, (Config[\"img_h\"], Config[\"img_w\"]))\n",
    "    val_dataset = YoloDataset(val_lines, (Config[\"img_h\"], Config[\"img_w\"]))\n",
    "    gen = DataLoader(train_dataset, batch_size=Batch_size, num_workers=8, pin_memory=True,\n",
    "                            drop_last=True, collate_fn=yolo_dataset_collate)\n",
    "    gen_val = DataLoader(val_dataset, batch_size=Batch_size, num_workers=8,pin_memory=True, \n",
    "                            drop_last=True, collate_fn=yolo_dataset_collate)\n",
    "else:\n",
    "    gen = Generator(Batch_size, train_lines,\n",
    "                        (Config[\"img_h\"], Config[\"img_w\"])).generate()\n",
    "    gen_val = Generator(Batch_size, val_lines,\n",
    "                        (Config[\"img_h\"], Config[\"img_w\"])).generate()\n",
    "                        \n",
    "epoch_size = num_train//Batch_size\n",
    "epoch_size_val = num_val//Batch_size\n",
    "for param in model.backbone.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "best_loss = 99999999.0\n",
    "best_model_weights = copy.deepcopy(model.state_dict())\n",
    "for epoch in range(Init_Epoch, Freeze_Epoch):\n",
    "    total_loss, val_loss = fit_one_epoch(net, yolo_losses, epoch, epoch_size, epoch_size_val, gen, gen_val, \n",
    "                                         Freeze_Epoch, Cuda, optimizer, lr_scheduler)\n",
    "    if total_loss < best_loss:\n",
    "        best_loss = total_loss\n",
    "        best_model_weights = copy.deepcopy(model.state_dict())\n",
    "    with open('total_loss.csv', mode='a+') as total_loss_file:\n",
    "        total_loss_file.write(str(total_loss.item()) + '\\n')\n",
    "    #with open('val_loss.csv', mode='a+') as val_loss_file:\n",
    "    #    val_loss_file.write(str(val_loss.item()) + '\\n')\n",
    "torch.save(best_model_weights, 'model_data/yolov3_voc_weights0.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------#\n",
    "#   解冻后训练\n",
    "#------------------------------------#            \n",
    "lr = 1e-4\n",
    "Batch_size = 16\n",
    "Freeze_Epoch = 25\n",
    "Unfreeze_Epoch = 50\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr)\n",
    "#optimizer = optim.SGD(net.parameters(), lr, momentum=0.9, weight_decay=0.0005)\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)\n",
    "if Use_Data_Loader:\n",
    "    train_dataset = YoloDataset(train_lines, (Config[\"img_h\"], Config[\"img_w\"]))\n",
    "    val_dataset = YoloDataset(val_lines, (Config[\"img_h\"], Config[\"img_w\"]))\n",
    "    gen = DataLoader(train_dataset, batch_size=Batch_size, num_workers=8, pin_memory=True,\n",
    "                            drop_last=True, collate_fn=yolo_dataset_collate)\n",
    "    gen_val = DataLoader(val_dataset, batch_size=Batch_size, num_workers=8,pin_memory=True, \n",
    "                            drop_last=True, collate_fn=yolo_dataset_collate)\n",
    "else:\n",
    "    gen = Generator(Batch_size, train_lines,\n",
    "                        (Config[\"img_h\"], Config[\"img_w\"])).generate()\n",
    "    gen_val = Generator(Batch_size, val_lines,\n",
    "                        (Config[\"img_h\"], Config[\"img_w\"])).generate()\n",
    "                        \n",
    "epoch_size = num_train//Batch_size\n",
    "epoch_size_val = num_val//Batch_size\n",
    "for param in model.backbone.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for epoch in range(Freeze_Epoch, Unfreeze_Epoch):\n",
    "    total_loss, val_loss = fit_one_epoch(net, yolo_losses, epoch, epoch_size, epoch_size_val, gen, gen_val, \n",
    "                                         Unfreeze_Epoch, Cuda, optimizer, lr_scheduler)\n",
    "    if total_loss < best_loss:\n",
    "        best_loss = total_loss\n",
    "        best_model_weights = copy.deepcopy(model.state_dict())\n",
    "    with open('total_loss.csv', mode='a+') as total_loss_file:\n",
    "        total_loss_file.write(str(total_loss.item()) + '\\n')\n",
    "    #with open('val_loss.csv', mode='a+') as val_loss_file:\n",
    "    #    val_loss_file.write(str(val_loss.item()) + '\\n')\n",
    "torch.save(best_model_weights, 'model_data/yolov3_voc_weights1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
